{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WUaYKEIeNUCw",
        "outputId": "3c6e3742-e892-4957-8e5e-1e20de06e8af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tigramite\n",
            "  Downloading tigramite-5.2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.17.0)\n",
            "Downloading tigramite-5.2.7.0-py3-none-any.whl (309 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.6/309.6 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tigramite\n",
            "Successfully installed tigramite-5.2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tigramite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tigramite import plotting as tp\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from scipy import stats"
      ],
      "metadata": {
        "id": "luH0rASqNofe"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_linear_equations(n_vars, max_lag):\n",
        "    \"\"\"Get linear equations for specified configuration with confounder\"\"\"\n",
        "    if n_vars == 4:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-2] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-2] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-4] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    elif n_vars == 6:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-2] + 0.3 * X5[t-1] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-2] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-4] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    elif n_vars == 8:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * X7[t] + 0.35 * U[t] + e8\",\n",
        "                \"X7[t] = 0.35 * X6[t-1] + e7\",\n",
        "                \"X6[t] = 0.45 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-2] + 0.3 * X5[t-1] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * X7[t] + 0.35 * U[t] + e8\",\n",
        "                \"X7[t] = 0.35 * X6[t-1] + e7\",\n",
        "                \"X6[t] = 0.45 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-2] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * X7[t] + 0.35 * U[t] + e8\",\n",
        "                \"X7[t] = 0.35 * X6[t-1] + e7\",\n",
        "                \"X6[t] = 0.45 * X5[t] + 0.4 * U[t] + e6\",\n",
        "                \"X5[t] = e5\",  # exogenous\n",
        "                \"X4[t] = 0.25 * X1[t-4] + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t] + 0.2 * X2[t-3] + 0.3 * U[t] + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1] + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t] + 0.5 * U[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    return []\n",
        "\n",
        "class LinearTimeSeriesGenerator:\n",
        "    def __init__(self, noise_type='gaussian', noise_scale=0.1, df=3, random_state=None):\n",
        "        \"\"\"\n",
        "        Initialize time series generator with specified noise type\n",
        "\n",
        "        Parameters:\n",
        "        noise_type: str, 'gaussian' or 'student_t'\n",
        "        noise_scale: float, scale parameter for noise distribution\n",
        "        df: int, degrees of freedom for Student's t-distribution (used only if noise_type='student_t')\n",
        "        random_state: int, random seed\n",
        "        \"\"\"\n",
        "        self.noise_type = noise_type\n",
        "        self.noise_scale = noise_scale\n",
        "        self.df = df  # Degrees of freedom for t-distribution\n",
        "        self.random_state = random_state\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "            if noise_type == 'student_t':\n",
        "                stats.t.random_state = np.random.RandomState(random_state)\n",
        "\n",
        "    def generate_noise(self, size):\n",
        "        \"\"\"Generate noise from specified distribution\"\"\"\n",
        "        if self.noise_type == 'gaussian':\n",
        "            return np.random.normal(0, self.noise_scale, size=size)\n",
        "        elif self.noise_type == 'student_t':\n",
        "            return stats.t.rvs(df=self.df, loc=0, scale=self.noise_scale, size=size)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown noise type: {self.noise_type}\")\n",
        "\n",
        "    def generate_linear_equations(self, t, X, U, n_vars, max_lag):\n",
        "        \"\"\"Execute linear equations with confounder\"\"\"\n",
        "        noise = self.generate_noise(n_vars + 1)  # +1 for U\n",
        "        equations = get_linear_equations(n_vars, max_lag)\n",
        "        var_values = {}\n",
        "\n",
        "        # Generate U first (confounder)\n",
        "        U[t] = noise[-1]\n",
        "        var_values['U'] = U[t]\n",
        "\n",
        "        # Generate X5 if present (exogenous)\n",
        "        if n_vars >= 6:\n",
        "            X[t, 4] = noise[4]  # X5 is exogenous\n",
        "            var_values['X5'] = X[t, 4]\n",
        "\n",
        "        # Process other variables in the right order to respect dependencies\n",
        "        # For most cases: X4 -> X3 -> X2 -> X1 -> X6 -> X7 -> X8\n",
        "\n",
        "        # Process variables from highest to lowest index (except already handled)\n",
        "        processed_indices = set()\n",
        "        if n_vars >= 6:\n",
        "            processed_indices.add(4)  # X5 already processed\n",
        "\n",
        "        remaining_indices = list(range(n_vars))\n",
        "        remaining_indices.reverse()  # Process from highest to lowest\n",
        "\n",
        "        while remaining_indices:\n",
        "            var_idx = remaining_indices[0]\n",
        "            var_name = f\"X{var_idx+1}\"\n",
        "\n",
        "            # Skip already processed\n",
        "            if var_idx in processed_indices:\n",
        "                remaining_indices.pop(0)\n",
        "                continue\n",
        "\n",
        "            # Find the equation for this variable\n",
        "            eq = None\n",
        "            for equation in equations:\n",
        "                if equation.startswith(var_name):\n",
        "                    eq = equation\n",
        "                    break\n",
        "\n",
        "            if not eq:\n",
        "                # No equation found, move to next\n",
        "                remaining_indices.pop(0)\n",
        "                continue\n",
        "\n",
        "            # Check if all dependencies are available\n",
        "            left, right = eq.split('=')\n",
        "            terms = [term.strip() for term in right.split('+')]\n",
        "\n",
        "            all_deps_available = True\n",
        "            for term in terms:\n",
        "                if not (term.startswith('e') or 'U[t]' in term):\n",
        "                    term_parts = term.split('*')\n",
        "                    if len(term_parts) < 2:\n",
        "                        continue\n",
        "\n",
        "                    var_part = term_parts[1].strip()\n",
        "                    if '[t]' in var_part:\n",
        "                        dep_name = var_part.split('[')[0]\n",
        "                        if dep_name not in var_values:\n",
        "                            all_deps_available = False\n",
        "                            break\n",
        "\n",
        "            if not all_deps_available:\n",
        "                # Move this to the end and try again later\n",
        "                remaining_indices.pop(0)\n",
        "                remaining_indices.append(var_idx)\n",
        "                continue\n",
        "\n",
        "            # Now compute the variable value\n",
        "            value = 0.0\n",
        "\n",
        "            for term in terms:\n",
        "                if term.startswith('e'):  # Noise term\n",
        "                    value += noise[var_idx]\n",
        "                else:\n",
        "                    # Parse coefficient and variable\n",
        "                    parts = term.split('*')\n",
        "                    coef = float(parts[0].strip())\n",
        "                    var = parts[1].strip()\n",
        "\n",
        "                    if 'U[t]' in var:\n",
        "                        # Confounder term\n",
        "                        value += coef * U[t]\n",
        "                    else:\n",
        "                        source_name = var.split('[')[0].strip()\n",
        "                        time_idx = var.split('[')[1].split(']')[0].strip()\n",
        "                        source_idx = int(source_name[1:]) - 1\n",
        "\n",
        "                        if time_idx == 't':\n",
        "                            # Current timestep dependency\n",
        "                            if source_name in var_values:\n",
        "                                # Use already computed value\n",
        "                                value += coef * var_values[source_name]\n",
        "                            else:\n",
        "                                # Use value from X if not yet computed in this timestep\n",
        "                                value += coef * X[t, source_idx]\n",
        "                        else:\n",
        "                            # Past timestep dependency\n",
        "                            lag = int(time_idx.split('-')[1])\n",
        "                            value += coef * X[t-lag, source_idx]\n",
        "\n",
        "            # Store the computed value\n",
        "            X[t, var_idx] = value\n",
        "            var_values[var_name] = value\n",
        "            processed_indices.add(var_idx)\n",
        "            remaining_indices.pop(0)\n",
        "\n",
        "    def generate_multivariate_ts(self, n_points, n_vars, max_lag):\n",
        "        \"\"\"Generate multivariate time series with regular sampling and confounder\"\"\"\n",
        "        X = np.zeros((n_points, n_vars))\n",
        "        U = np.zeros(n_points)  # Array for confounder U\n",
        "\n",
        "        # Initialize first steps with noise\n",
        "        for i in range(max_lag):\n",
        "            X[i] = self.generate_noise(n_vars)\n",
        "            U[i] = self.generate_noise(1)[0]\n",
        "\n",
        "        # Generate time series\n",
        "        for t in range(max_lag, n_points):\n",
        "            self.generate_linear_equations(t, X, U, n_vars, max_lag)\n",
        "\n",
        "        # Create DataFrame\n",
        "        timestamps = np.arange(n_points)\n",
        "        columns = [f'X{i+1}' for i in range(n_vars)]\n",
        "        df = pd.DataFrame(X, columns=columns)\n",
        "        df['U'] = U\n",
        "        df['time'] = timestamps\n",
        "\n",
        "        return df\n",
        "\n",
        "def extract_linear_links(equations):\n",
        "    \"\"\"Extract all linear causal links from the equations\"\"\"\n",
        "    links = {}\n",
        "\n",
        "    for eq in equations:\n",
        "        if '=' in eq:\n",
        "            left, right = [side.strip() for side in eq.split('=')]\n",
        "            target = left.split('[')[0]\n",
        "\n",
        "            if target != 'U':  # Skip U's equation\n",
        "                terms = [term.strip() for term in right.split('+')]\n",
        "                for term in terms:\n",
        "                    if '*' in term and ('X' in term or 'U' in term):\n",
        "                        parts = term.split('*')\n",
        "                        coeff = float(parts[0].strip())\n",
        "                        var_part = parts[1].strip()\n",
        "                        var = var_part.split('[')[0]\n",
        "                        lag_part = var_part.split('[')[1].split(']')[0]\n",
        "\n",
        "                        lag = 0 if lag_part == 't' else -int(lag_part.split('-')[1])\n",
        "                        links[(var, lag, target)] = coeff\n",
        "\n",
        "    return links\n",
        "\n",
        "def save_dataset_and_graph(df, n_vars, max_lag, sample_size, noise_type, output_dir=\"output\"):\n",
        "    \"\"\"Save dataset and create causal graph\"\"\"\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Save dataset\n",
        "    filename = f'{output_dir}/linear_ts_with_confounder_n{sample_size}_vars{n_vars}_lag{max_lag}_{noise_type}.csv'\n",
        "    df.to_csv(filename, index=False)\n",
        "\n",
        "    # Get equations and extract links\n",
        "    equations = get_linear_equations(n_vars, max_lag)\n",
        "    true_links = extract_linear_links(equations)\n",
        "\n",
        "    # Create matrices for tigramite plotting\n",
        "    var_names = [f'X{i+1}' for i in range(n_vars)] + ['U']\n",
        "    n_total_vars = n_vars + 1\n",
        "    val_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1))\n",
        "    graph_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1), dtype='bool')\n",
        "\n",
        "    # Fill matrices based on true links\n",
        "    for (source, lag, target), weight in true_links.items():\n",
        "        if source == 'U':\n",
        "            source_idx = n_vars\n",
        "        else:\n",
        "            source_idx = int(source[1:]) - 1\n",
        "\n",
        "        target_idx = int(target[1:]) - 1\n",
        "        lag_idx = abs(lag)\n",
        "\n",
        "        # Add the link to the matrices\n",
        "        val_matrix[source_idx, target_idx, lag_idx] = weight\n",
        "        graph_matrix[source_idx, target_idx, lag_idx] = True\n",
        "\n",
        "        # For contemporaneous links, make val_matrix symmetric\n",
        "        if lag == 0:\n",
        "            val_matrix[target_idx, source_idx, lag_idx] = weight\n",
        "\n",
        "    # Plot and save causal graph\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    tp.plot_time_series_graph(\n",
        "        val_matrix=val_matrix,\n",
        "        graph=graph_matrix,\n",
        "        var_names=var_names,\n",
        "        link_colorbar_label='Linear Effect Strength',\n",
        "        node_size=0.05\n",
        "    )\n",
        "    plt.title(f'Linear Causal Graph with Confounder (n={sample_size}, vars={n_vars}, lag={max_lag}, {noise_type} noise)')\n",
        "    plt.savefig(f'{output_dir}/linear_causal_graph_with_confounder_n{sample_size}_vars{n_vars}_lag{max_lag}_{noise_type}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot time series\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for col in df.columns[:-2]:  # Exclude U and time columns\n",
        "        plt.plot(df['time'], df[col], label=col, alpha=0.7)\n",
        "    plt.title(f'Linear Time Series with {noise_type.capitalize()} Errors (n={sample_size}, vars={n_vars}, lag={max_lag})')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{output_dir}/linear_ts_plot_with_confounder_n{sample_size}_vars{n_vars}_lag{max_lag}_{noise_type}.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save causal structure description\n",
        "    with open(f'{output_dir}/linear_causal_structure_with_confounder_vars{n_vars}_lag{max_lag}_{noise_type}.txt', 'w') as f:\n",
        "        f.write(f\"True Linear Causal Structure with Confounder and {noise_type.capitalize()} Noise:\\n\")\n",
        "        f.write(\"Format: (source, lag, target) => coefficient\\n\")\n",
        "        f.write(\"\\nEquations:\\n\")\n",
        "        for eq in equations:\n",
        "            f.write(f\"{eq}\\n\")\n",
        "        f.write(\"\\nCausal Links:\\n\")\n",
        "        for (source, lag, target), coef in true_links.items():\n",
        "            f.write(f\"({source}, {lag}, {target}) => {coef}\\n\")\n",
        "\n",
        "def generate_all_combinations():\n",
        "    \"\"\"Generate datasets for all combinations\"\"\"\n",
        "    n_vars_list = [4, 6, 8]\n",
        "    max_lags = [2, 3, 4]\n",
        "    sample_sizes = [500, 1000, 3000, 5000]\n",
        "    noise_types = ['gaussian', 'student_t']\n",
        "\n",
        "    for n in sample_sizes:\n",
        "        for vars in n_vars_list:\n",
        "            for lag in max_lags:\n",
        "                for noise_type in noise_types:\n",
        "                    print(f\"\\nGenerating dataset: n={n}, vars={vars}, lag={lag}, noise={noise_type}\")\n",
        "\n",
        "                    # Generate dataset with specified noise distribution\n",
        "                    if noise_type == 'gaussian':\n",
        "                        generator = LinearTimeSeriesGenerator(\n",
        "                            noise_type='gaussian',\n",
        "                            noise_scale=0.1,\n",
        "                            random_state=42\n",
        "                        )\n",
        "                    else:  # student_t\n",
        "                        generator = LinearTimeSeriesGenerator(\n",
        "                            noise_type='student_t',\n",
        "                            noise_scale=0.1,\n",
        "                            df=3,\n",
        "                            random_state=42\n",
        "                        )\n",
        "\n",
        "                    df = generator.generate_multivariate_ts(\n",
        "                        n_points=n,\n",
        "                        n_vars=vars,\n",
        "                        max_lag=lag\n",
        "                    )\n",
        "\n",
        "                    # Save dataset and create visualizations\n",
        "                    save_dataset_and_graph(df, vars, lag, n, noise_type)\n",
        "                    print(f\"Dataset and visualizations saved successfully\")\n",
        "\n",
        "# Function to verify generation is working properly\n",
        "def test_generator(n_points=20, n_vars=4, max_lag=2, noise_type='gaussian'):\n",
        "    \"\"\"Function to test and verify the generator is working correctly\"\"\"\n",
        "    generator = LinearTimeSeriesGenerator(\n",
        "        noise_type=noise_type,\n",
        "        noise_scale=0.1,\n",
        "        random_state=42\n",
        "    )\n",
        "\n",
        "    df = generator.generate_multivariate_ts(\n",
        "        n_points=n_points,\n",
        "        n_vars=n_vars,\n",
        "        max_lag=max_lag\n",
        "    )\n",
        "\n",
        "    print(f\"Generated time series with shape: {df.shape}\")\n",
        "    print(\"\\nSample of generated data:\")\n",
        "    print(df.head(10))\n",
        "\n",
        "    # Check if there are any zeros (indicating potential issues)\n",
        "    all_zeros = (df.iloc[:, :n_vars] == 0).all().any()\n",
        "    if all_zeros:\n",
        "        print(\"\\nWARNING: Found columns with all zeros!\")\n",
        "    else:\n",
        "        print(\"\\nNo columns with all zeros detected.\")\n",
        "\n",
        "    # Basic statistical check\n",
        "    print(\"\\nBasic statistics:\")\n",
        "    print(df.iloc[:, :n_vars].describe())\n",
        "\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "eHl0XH4wNozv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # First run a test to verify everything works\n",
        "    print(\"Testing generator with small dataset...\")\n",
        "    test_df = test_generator(n_points=50, n_vars=4, max_lag=2, noise_type='gaussian')\n",
        "\n",
        "    # If everything looks good, generate all combinations\n",
        "    print(\"\\nStarting generation of all combinations...\")\n",
        "    generate_all_combinations()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ovhUnbN_NpC_",
        "outputId": "418b964e-5a7c-459b-f0b5-a04996f61b3b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing generator with small dataset...\n",
            "Generated time series with shape: (50, 6)\n",
            "\n",
            "Sample of generated data:\n",
            "         X1        X2        X3        X4         U  time\n",
            "0  0.049671 -0.013826  0.064769  0.152303 -0.023415     0\n",
            "1 -0.023414  0.157921  0.076743 -0.046947  0.054256     1\n",
            "2 -0.142008 -0.023550 -0.090170 -0.178910 -0.172492     2\n",
            "3 -0.178178 -0.128334 -0.044774 -0.096656 -0.141230     3\n",
            "4  0.104942 -0.036010 -0.071871 -0.177977 -0.054438     4\n",
            "5 -0.058157 -0.136661 -0.007794 -0.104608 -0.029169     5\n",
            "6  0.054112  0.182890 -0.004511 -0.079536  0.082254     6\n",
            "7 -0.104428  0.019533 -0.241636 -0.147358  0.019686     7\n",
            "8 -0.022221 -0.055354 -0.061724 -0.016582 -0.147852     8\n",
            "9 -0.185969 -0.064581  0.055710  0.008255 -0.176304     9\n",
            "\n",
            "No columns with all zeros detected.\n",
            "\n",
            "Basic statistics:\n",
            "              X1         X2         X3         X4\n",
            "count  50.000000  50.000000  50.000000  50.000000\n",
            "mean    0.004605   0.002396  -0.002106  -0.007548\n",
            "std     0.101130   0.096618   0.090392   0.093896\n",
            "min    -0.205697  -0.194730  -0.241636  -0.190512\n",
            "25%    -0.048291  -0.044661  -0.062729  -0.068088\n",
            "50%     0.027255  -0.005884  -0.007063  -0.014670\n",
            "75%     0.072926   0.062808   0.057009   0.052821\n",
            "max     0.220598   0.184690   0.222143   0.205359\n",
            "\n",
            "Starting generation of all combinations...\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, noise=student_t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tigramite/plotting.py:3203: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig = pyplot.figure(figsize=figsize)\n",
            "<ipython-input-3-142a138f26a8>:334: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(15, 10))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, noise=gaussian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-142a138f26a8>:321: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(12, 12))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, noise=student_t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, noise=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, noise=student_t\n",
            "Dataset and visualizations saved successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/output_A1C.zip /content/output\n",
        "from google.colab import files\n",
        "files.download('/content/output_A1C.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OdK4VWB0Ow3r",
        "outputId": "967e9c5f-8eba-47e2-85b6-e269b29aa560"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag3_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag3_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag3_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag3_gaussian.txt (deflated 46%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag4_gaussian.txt (deflated 46%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag3_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag3_student_t.png (deflated 8%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag3_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag4_student_t.txt (deflated 52%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag2_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag2_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag3_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag4_student_t.txt (deflated 42%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag2_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag3_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag2_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag4_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag3_gaussian.txt (deflated 42%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag4_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag3_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag3_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag4_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag3_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag3_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag4_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag2_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag3_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag3_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag4_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag4_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag2_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag2_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag2_gaussian.txt (deflated 40%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag3_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag4_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag4_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag2_student_t.txt (deflated 40%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag4_student_t.txt (deflated 47%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag4_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag3_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag4_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag4_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag3_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag2_gaussian.txt (deflated 48%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag4_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag3_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag2_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag4_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag3_student_t.txt (deflated 47%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag4_student_t.png (deflated 7%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars4_lag2_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag4_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag3_student_t.txt (deflated 42%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag2_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag2_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag2_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag4_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars8_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars8_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag3_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag3_student_t.txt (deflated 52%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag3_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag3_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars4_lag3_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars4_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars4_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag4_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars8_lag2_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars8_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars4_lag4_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag2_student_t.txt (deflated 53%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars4_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars6_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n3000_vars6_lag2_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars8_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars8_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars6_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars6_lag3_gaussian.png (deflated 1%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars8_lag4_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag3_gaussian.txt (deflated 52%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars8_lag4_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars8_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag2_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag3_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars4_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars8_lag3_student_t.csv (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag2_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars6_lag3_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars4_lag2_student_t.png (deflated 5%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars6_lag2_student_t.txt (deflated 48%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars6_lag2_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n500_vars6_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag2_gaussian.txt (deflated 53%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag3_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars4_lag4_gaussian.txt (deflated 42%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag3_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n5000_vars4_lag2_student_t.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_structure_with_confounder_vars8_lag4_gaussian.txt (deflated 52%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag2_student_t.png (deflated 7%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n500_vars4_lag4_student_t.png (deflated 3%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n1000_vars6_lag3_gaussian.png (deflated 2%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars6_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_ts_with_confounder_n1000_vars6_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n500_vars8_lag4_student_t.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n1000_vars4_lag3_gaussian.png (deflated 4%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n3000_vars6_lag2_gaussian.png (deflated 5%)\n",
            "  adding: content/output/linear_ts_with_confounder_n3000_vars4_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/linear_ts_plot_with_confounder_n5000_vars8_lag2_gaussian.png (deflated 3%)\n",
            "  adding: content/output/linear_causal_graph_with_confounder_n5000_vars6_lag3_student_t.png (deflated 4%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_43517304-1372-4c7d-ba6a-5886f78c8363\", \"output_A1C.zip\", 32765670)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}