{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjOIMsrVbcN2",
        "outputId": "c4244096-c068-4435-90e9-00ba565d31c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tigramite\n",
            "  Downloading tigramite-5.2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.17.0)\n",
            "Downloading tigramite-5.2.7.0-py3-none-any.whl (309 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.6/309.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tigramite\n",
            "Successfully installed tigramite-5.2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tigramite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from tigramite import plotting as tp\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "7m60SBz4bkhx"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_nonlinear_equations(n_vars, max_lag):\n",
        "    \"\"\"Get nonlinear equations with confounder U\"\"\"\n",
        "    if n_vars == 4:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-2]^2 - 0.1 * X1[t-2]^3 + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t]^2 - 0.15 * X4[t]^3 + 0.3 * U[t]^2 + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1]^2 - 0.05 * X3[t-1]^3 + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t]^2 - 0.2 * X2[t]^3 + 0.5 * U[t]^2 + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-2]^2 - 0.1 * X1[t-2]^3 + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t]^2 - 0.15 * X4[t]^3 + 0.2 * X2[t-3]^2 + 0.3 * U[t]^2 + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1]^2 - 0.05 * X3[t-1]^3 + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t]^2 - 0.2 * X2[t]^3 + 0.5 * U[t]^2 + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * X1[t-4]^2 - 0.1 * X1[t-4]^3 + e4\",\n",
        "                \"X3[t] = 0.35 * X4[t]^2 - 0.15 * X4[t]^3 + 0.2 * X2[t-3]^2 + 0.3 * U[t]^2 + e3\",\n",
        "                \"X2[t] = 0.3 * X3[t-1]^2 - 0.05 * X3[t-1]^3 + e2\",\n",
        "                \"X1[t] = 0.4 * X2[t]^2 - 0.2 * X2[t]^3 + 0.5 * U[t]^2 + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    elif n_vars == 6:\n",
        "        base_equations = get_nonlinear_equations(4, max_lag)\n",
        "        additional = [\n",
        "            \"X6[t] = 0.45 * X5[t]^2 - 0.15 * X5[t]^3 + 0.4 * U[t]^2 + e6\",\n",
        "            \"X5[t] = 0.3 * X4[t-1]^2 - 0.1 * X4[t-1]^3 + e5\"\n",
        "        ]\n",
        "        return additional + base_equations\n",
        "    elif n_vars == 8:\n",
        "        base_equations = get_nonlinear_equations(6, max_lag)\n",
        "        additional = [\n",
        "            \"X8[t] = 0.4 * X7[t]^2 - 0.12 * X7[t]^3 + 0.35 * U[t]^2 + e8\",\n",
        "            \"X7[t] = 0.35 * X6[t-1]^2 - 0.08 * X6[t-1]^3 + e7\"\n",
        "        ]\n",
        "        return additional + base_equations\n",
        "    return []\n",
        "\n",
        "def extract_linear_links(equations):\n",
        "    \"\"\"Extract all linear and nonlinear causal links from the equations\"\"\"\n",
        "    links = {}\n",
        "\n",
        "    for eq in equations:\n",
        "        if '=' in eq:\n",
        "            left, right = [side.strip() for side in eq.split('=')]\n",
        "            target = left.split('[')[0]\n",
        "\n",
        "            if target != 'U':  # Skip U's equation\n",
        "                terms = [term.strip() for term in right.split('+')]\n",
        "                for term in terms:\n",
        "                    if '*' in term and ('X' in term or 'U' in term):\n",
        "                        # Extract coefficient and variable\n",
        "                        coeff = float(term.split('*')[0].strip())\n",
        "                        var_part = term.split('*')[1].strip()\n",
        "\n",
        "                        # Handle power terms by taking only the base variable\n",
        "                        var = var_part.split('^')[0].split('[')[0]\n",
        "                        lag_part = var_part.split('[')[1].split(']')[0]\n",
        "\n",
        "                        # Get lag\n",
        "                        lag = 0 if lag_part == 't' else -int(lag_part.split('-')[1])\n",
        "\n",
        "                        # Store the link with its base coefficient\n",
        "                        key = (var, lag, target)\n",
        "                        if key not in links:\n",
        "                            links[key] = 0\n",
        "                        links[key] += coeff  # Sum coefficients if multiple terms\n",
        "\n",
        "    return links\n",
        "\n",
        "class NonlinearConfoundedGenerator:\n",
        "    def __init__(self, error_dist='gaussian', noise_params={'scale': 0.1, 'df': 3}, random_state=None):\n",
        "        self.error_dist = error_dist\n",
        "        self.noise_params = noise_params\n",
        "        self.random_state = random_state\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "\n",
        "    def generate_noise(self, size):\n",
        "        if self.error_dist == 'gaussian':\n",
        "            return np.random.normal(0, self.noise_params['scale'], size=size)\n",
        "        elif self.error_dist == 't':\n",
        "            return stats.t.rvs(df=self.noise_params['df'],\n",
        "                             scale=self.noise_params['scale'],\n",
        "                             size=size,\n",
        "                             random_state=self.random_state)\n",
        "\n",
        "    def generate_equations(self, t, X, U, n_vars, max_lag):\n",
        "        noise = self.generate_noise(n_vars + 1)  # +1 for U\n",
        "        equations = get_nonlinear_equations(n_vars, max_lag)\n",
        "        true_links = extract_coefficients_from_equations(equations)\n",
        "\n",
        "        # Generate U first as it's a confounder\n",
        "        U[t] = noise[-1]\n",
        "\n",
        "        # Generate values based on nonlinear relationships\n",
        "        for i in range(n_vars-1, -1, -1):\n",
        "            var_name = f'X{i+1}'\n",
        "            value = 0\n",
        "\n",
        "            # Add causal influences with polynomial terms\n",
        "            for (source, lag, target, power), coef in true_links.items():\n",
        "                if target == var_name:\n",
        "                    if source == 'U':\n",
        "                        value += coef * (U[t] ** power)\n",
        "                    else:\n",
        "                        source_idx = int(source[1:]) - 1\n",
        "                        if lag == 0:\n",
        "                            value += coef * (X[t, source_idx] ** power)\n",
        "                        else:\n",
        "                            value += coef * (X[t + lag, source_idx] ** power)\n",
        "\n",
        "            # Add noise term\n",
        "            X[t, i] = value + noise[i]\n",
        "\n",
        "    def generate_multivariate_ts(self, n_points, n_vars, max_lag):\n",
        "        # Initialize arrays\n",
        "        X = np.zeros((n_points, n_vars))\n",
        "        U = np.zeros(n_points)  # Array for confounder U\n",
        "\n",
        "        # Initialize first steps with noise\n",
        "        for i in range(max_lag):\n",
        "            X[i] = self.generate_noise(n_vars)\n",
        "            U[i] = self.generate_noise(1)[0]\n",
        "\n",
        "        # Generate time series\n",
        "        for t in range(max_lag, n_points):\n",
        "            self.generate_equations(t, X, U, n_vars, max_lag)\n",
        "\n",
        "        # Create DataFrame\n",
        "        columns = [f'X{i+1}' for i in range(n_vars)] + ['U']\n",
        "        df = pd.DataFrame(np.column_stack([X, U[:, np.newaxis]]), columns=columns)\n",
        "        df['time'] = np.arange(n_points)\n",
        "\n",
        "        return df\n",
        "\n",
        "def extract_coefficients_from_equations(equations):\n",
        "    \"\"\"Extract coefficients and causal relationships from equations\"\"\"\n",
        "    causal_links = {}\n",
        "\n",
        "    for eq in equations:\n",
        "        if '=' not in eq:\n",
        "            continue\n",
        "\n",
        "        left, right = [side.strip() for side in eq.split('=')]\n",
        "        if 'e' in right and len(right.split('+')) == 1:\n",
        "            continue  # Skip pure noise equations\n",
        "\n",
        "        target = left.split('[')[0]\n",
        "        terms = [term.strip() for term in right.split('+')]\n",
        "\n",
        "        for term in terms:\n",
        "            if '*' not in term or not ('X' in term or 'U' in term):\n",
        "                continue\n",
        "\n",
        "            # Split coefficient and variable part\n",
        "            parts = term.split('*')\n",
        "            coeff = float(parts[0].strip())\n",
        "            var_part = parts[1].strip()\n",
        "\n",
        "            # Extract variable name and power\n",
        "            base_var = var_part.split('^')[0] if '^' in var_part else var_part\n",
        "            var = base_var.split('[')[0]\n",
        "\n",
        "            # Get power\n",
        "            power = 1\n",
        "            if '^' in var_part:\n",
        "                power = int(var_part.split('^')[1].split(' ')[0])\n",
        "\n",
        "            # Get lag\n",
        "            if var == 'U':\n",
        "                lag = 0\n",
        "            else:\n",
        "                lag_part = base_var.split('[')[1].split(']')[0]\n",
        "                lag = 0 if lag_part == 't' else -int(lag_part.split('-')[1])\n",
        "\n",
        "            causal_links[(var, lag, target, power)] = coeff\n",
        "\n",
        "    return causal_links\n",
        "\n",
        "def save_dataset_and_graph(df, n_vars, max_lag, sample_size, error_dist, output_dir=\"output\"):\n",
        "    \"\"\"Save dataset and create causal graph\"\"\"\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    base_filename = f'{output_dir}/nonlinear_confounded_n{sample_size}_vars{n_vars}_lag{max_lag}_{error_dist}'\n",
        "\n",
        "    # Save dataset\n",
        "    df.to_csv(f'{base_filename}.csv', index=False)\n",
        "\n",
        "    # Get equations and extract links\n",
        "    equations = get_nonlinear_equations(n_vars, max_lag)\n",
        "    true_links = extract_linear_links(equations)\n",
        "\n",
        "    # Create variable names including U\n",
        "    var_names = [f'X{i+1}' for i in range(n_vars)] + ['U']\n",
        "    n_total_vars = n_vars + 1\n",
        "    val_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1))\n",
        "    graph_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1), dtype='bool')\n",
        "\n",
        "    # Fill matrices based on true links\n",
        "    for (source, lag, target), weight in true_links.items():\n",
        "        if source == 'U':\n",
        "            source_idx = n_vars\n",
        "        else:\n",
        "            source_idx = int(source[1:]) - 1\n",
        "\n",
        "        target_idx = int(target[1:]) - 1\n",
        "        lag_idx = abs(lag)\n",
        "\n",
        "        # Add the link to the matrices\n",
        "        val_matrix[source_idx, target_idx, lag_idx] = weight\n",
        "        graph_matrix[source_idx, target_idx, lag_idx] = True\n",
        "\n",
        "        # For contemporaneous links, make val_matrix symmetric\n",
        "        if lag == 0:\n",
        "            val_matrix[target_idx, source_idx, lag_idx] = weight\n",
        "\n",
        "    # Plot and save causal graph\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    tp.plot_time_series_graph(\n",
        "        val_matrix=val_matrix,\n",
        "        graph=graph_matrix,\n",
        "        var_names=var_names,\n",
        "        link_colorbar_label='Nonlinear Effect Strength',\n",
        "        node_size=0.05\n",
        "    )\n",
        "    plt.title(f'Nonlinear Causal Graph (n={sample_size}, vars={n_vars}, lag={max_lag}, with confounder)')\n",
        "    plt.savefig(f'{base_filename}_graph.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot time series\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for col in df.columns[:-2]:  # Exclude U and time\n",
        "        plt.plot(df['time'], df[col], label=col, alpha=0.7)\n",
        "    plt.title(f'Time Series (n={sample_size}, vars={n_vars}, lag={max_lag})')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{base_filename}_series.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save causal structure\n",
        "    with open(f'{base_filename}_structure.txt', 'w') as f:\n",
        "        f.write(\"True Nonlinear Causal Structure with Confounder:\\n\")\n",
        "        f.write(\"Format: (source, lag, target) => weight\\n\")\n",
        "        for link, weight in true_links.items():\n",
        "            f.write(f\"{link} => {weight}\\n\")\n",
        "\n",
        "def analyze_generated_data(df, max_lag, title=\"Nonlinear Time Series Analysis\"):\n",
        "    \"\"\"Analyze and plot the generated time series data\"\"\"\n",
        "    print(f\"\\nAnalyzing {title}\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    # Time Series Plot\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for col in df.columns:\n",
        "        if col != 'time':\n",
        "            plt.plot(df['time'], df[col], label=col, alpha=0.7)\n",
        "    plt.title(f\"{title} - Time Series\")\n",
        "    plt.xlabel(\"Time\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    # Summary Statistics\n",
        "    print(\"\\nSummary Statistics:\")\n",
        "    print(\"-\" * 30)\n",
        "    print(df.drop('time', axis=1).describe())\n",
        "\n",
        "    # Correlation Analysis\n",
        "    print(\"\\nCorrelation with Confounder U:\")\n",
        "    print(\"-\" * 30)\n",
        "    u_corr = df.drop('time', axis=1).corr()['U'].sort_values(ascending=False)\n",
        "    print(u_corr)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # # Example analysis of a single case\n",
        "    # print(\"Generating example dataset with Gaussian noise...\")\n",
        "\n",
        "    # # Parameters for example\n",
        "    # n_points = 1000\n",
        "    # n_vars = 4\n",
        "    # max_lag = 2\n",
        "\n",
        "    # # Generate Gaussian example\n",
        "    # generator = NonlinearConfoundedGenerator(\n",
        "    #     error_dist='gaussian',\n",
        "    #     noise_params={'scale': 0.1},\n",
        "    #     random_state=42\n",
        "    # )\n",
        "\n",
        "    # df_gaussian = generator.generate_multivariate_ts(\n",
        "    #     n_points=n_points,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag\n",
        "    # )\n",
        "\n",
        "    # # Save and analyze Gaussian example\n",
        "    # save_dataset_and_graph(\n",
        "    #     df=df_gaussian,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag,\n",
        "    #     sample_size=n_points,\n",
        "    #     error_dist='gaussian'\n",
        "    # )\n",
        "\n",
        "    # analyze_generated_data(df_gaussian, max_lag, \"Gaussian Example\")\n",
        "\n",
        "    # # Generate Student's t example\n",
        "    # print(\"\\nGenerating example dataset with Student's t noise...\")\n",
        "    # generator_t = NonlinearConfoundedGenerator(\n",
        "    #     error_dist='t',\n",
        "    #     noise_params={'scale': 0.1, 'df': 3},\n",
        "    #     random_state=42\n",
        "    # )\n",
        "\n",
        "    # df_t = generator_t.generate_multivariate_ts(\n",
        "    #     n_points=n_points,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag\n",
        "    # )\n",
        "\n",
        "    # # Save and analyze t-distribution example\n",
        "    # save_dataset_and_graph(\n",
        "    #     df=df_t,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag,\n",
        "    #     sample_size=n_points,\n",
        "    #     error_dist='t'\n",
        "    # )\n",
        "\n",
        "    # analyze_generated_data(df_t, max_lag, \"Student's t Example\")\n",
        "\n",
        "    # Generate all combinations\n",
        "    def generate_all_combinations():\n",
        "        \"\"\"Generate datasets for all combinations\"\"\"\n",
        "        sample_sizes = [500, 1000, 3000, 5000]\n",
        "        n_vars_list = [4, 6, 8]\n",
        "        max_lags = [2, 3, 4]\n",
        "        error_dists = ['gaussian', 't']\n",
        "\n",
        "        for n in sample_sizes:\n",
        "            for vars in n_vars_list:\n",
        "                for lag in max_lags:\n",
        "                    for dist in error_dists:\n",
        "                        print(f\"\\nGenerating dataset: n={n}, vars={vars}, lag={lag}, dist={dist}\")\n",
        "\n",
        "                        noise_params = {'scale': 0.1, 'df': 3} if dist == 't' else {'scale': 0.1}\n",
        "                        generator = NonlinearConfoundedGenerator(\n",
        "                            error_dist=dist,\n",
        "                            noise_params=noise_params,\n",
        "                            random_state=42\n",
        "                        )\n",
        "\n",
        "                        df = generator.generate_multivariate_ts(\n",
        "                            n_points=n,\n",
        "                            n_vars=vars,\n",
        "                            max_lag=lag\n",
        "                        )\n",
        "\n",
        "                        save_dataset_and_graph(df, vars, lag, n, dist)\n",
        "                        print(\"Dataset and visualizations saved successfully\")\n",
        "\n",
        "    # Uncomment to generate all combinations\n",
        "    # print(\"\\nGenerating all combinations...\")\n",
        "    generate_all_combinations()"
      ],
      "metadata": {
        "id": "61TEY9TUlEob",
        "outputId": "f225df43-f125-4537-f399-74b05235b83c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, dist=t\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tigramite/plotting.py:3203: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig = pyplot.figure(figsize=figsize)\n",
            "<ipython-input-4-d698c621f5d4>:236: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(15, 10))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, dist=gaussian\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-d698c621f5d4>:223: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(12, 12))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, dist=t\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, dist=gaussian\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, dist=t\n",
            "Dataset and visualizations saved successfully\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# if __name__ == \"__main__\":\n",
        "    # # Example analysis of a single case\n",
        "    # print(\"Generating example dataset with Gaussian noise...\")\n",
        "\n",
        "    # # Parameters for example\n",
        "    # n_points = 1000\n",
        "    # n_vars = 4\n",
        "    # max_lag = 2\n",
        "\n",
        "    # # Generate Gaussian example\n",
        "    # generator = NonlinearConfoundedGenerator(\n",
        "    #     error_dist='gaussian',\n",
        "    #     noise_params={'scale': 0.1},\n",
        "    #     random_state=42\n",
        "    # )\n",
        "\n",
        "    # df_gaussian = generator.generate_multivariate_ts(\n",
        "    #     n_points=n_points,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag\n",
        "    # )\n",
        "\n",
        "    # # Save and analyze Gaussian example\n",
        "    # save_dataset_and_graph(\n",
        "    #     df=df_gaussian,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag,\n",
        "    #     sample_size=n_points,\n",
        "    #     error_dist='gaussian'\n",
        "    # )\n",
        "\n",
        "    # analyze_generated_data(df_gaussian, max_lag, \"Gaussian Example\")\n",
        "\n",
        "    # # Generate Student's t example\n",
        "    # print(\"\\nGenerating example dataset with Student's t noise...\")\n",
        "    # generator_t = NonlinearConfoundedGenerator(\n",
        "    #     error_dist='t',\n",
        "    #     noise_params={'scale': 0.1, 'df': 3},\n",
        "    #     random_state=42\n",
        "    # )\n",
        "\n",
        "    # df_t = generator_t.generate_multivariate_ts(\n",
        "    #     n_points=n_points,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag\n",
        "    # )\n",
        "\n",
        "    # # Save and analyze t-distribution example\n",
        "    # save_dataset_and_graph(\n",
        "    #     df=df_t,\n",
        "    #     n_vars=n_vars,\n",
        "    #     max_lag=max_lag,\n",
        "    #     sample_size=n_points,\n",
        "    #     error_dist='t'\n",
        "    # )\n",
        "\n",
        "    # analyze_generated_data(df_t, max_lag, \"Student's t Example\")"
      ],
      "metadata": {
        "id": "9k8APJ-clTSX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UuOEat2ktat2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/output.zip /content/output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CQ3PbfPRWez",
        "outputId": "3cf87cf5-6196-4245-85b0-59745119160b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output/ (stored 0%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_gaussian_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_gaussian_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_t_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_t_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_gaussian_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_gaussian_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_t_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_t_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_t.csv (deflated 96%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_t_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_t_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_gaussian_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_t_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_t_series.png (deflated 29%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_t_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_t_series.png (deflated 29%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_gaussian_series.png (deflated 2%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_t_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_t_series.png (deflated 29%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag3_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag2_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag3_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_t_series.png (deflated 33%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_gaussian.csv (deflated 53%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag2_t_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag3_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_t_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag4_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag4_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag4_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_t_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag4_t.csv (deflated 97%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_t_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_gaussian_series.png (deflated 1%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_t_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars4_lag4_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_gaussian.csv (deflated 55%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag2_gaussian_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_t_series.png (deflated 32%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag3_gaussian_structure.txt (deflated 40%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars8_lag4_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag2_t.csv (deflated 98%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars4_lag2_gaussian_structure.txt (deflated 37%)\n",
            "  adding: content/output/nonlinear_confounded_n3000_vars6_lag2_gaussian_structure.txt (deflated 46%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_t_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag3_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars6_lag4_gaussian_series.png (deflated 3%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag3_gaussian_structure.txt (deflated 48%)\n",
            "  adding: content/output/nonlinear_confounded_n5000_vars8_lag4_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag4_t_structure.txt (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag2_t_structure.txt (deflated 52%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag2_t_series.png (deflated 30%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars4_lag4_t.csv (deflated 96%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars8_lag4_t_series.png (deflated 31%)\n",
            "  adding: content/output/nonlinear_confounded_n500_vars6_lag2_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars8_lag2_gaussian.csv (deflated 54%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output/nonlinear_confounded_n1000_vars6_lag3_gaussian_structure.txt (deflated 48%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/output.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "l9HOt6cztvqd",
        "outputId": "0067947c-4c79-42d1-941c-ec507495b659"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1ab3a817-ad26-4c78-9e39-f37c98fbc12c\", \"output.zip\", 21697310)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}