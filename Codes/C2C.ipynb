{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpY5Fy_nf74_",
        "outputId": "a36f303b-d134-4f08-f20f-b5a86f1cc409"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tigramite\n",
            "  Downloading tigramite-5.2.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.18 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from tigramite) (1.17.0)\n",
            "Downloading tigramite-5.2.7.0-py3-none-any.whl (309 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/309.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/309.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.6/309.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tigramite\n",
            "Successfully installed tigramite-5.2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tigramite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from tigramite import plotting as tp\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path"
      ],
      "metadata": {
        "id": "hhsPGVEPf9tu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def get_nonlinear_equations_with_confounder(n_vars, max_lag):\n",
        "    \"\"\"Get nonlinear equations with confounder U (max 2 edges from U)\"\"\"\n",
        "    if n_vars == 4:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    elif n_vars == 6:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    elif n_vars == 8:\n",
        "        if max_lag == 2:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8\",\n",
        "                \"X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7\",\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 3:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8\",\n",
        "                \"X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7\",\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "        elif max_lag == 4:\n",
        "            return [\n",
        "                \"X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8\",\n",
        "                \"X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7\",\n",
        "                \"X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6\",\n",
        "                \"X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5\",\n",
        "                \"X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4\",\n",
        "                \"X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3\",\n",
        "                \"X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2\",\n",
        "                \"X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1\",\n",
        "                \"U[t] = eU\"\n",
        "            ]\n",
        "    return []\n",
        "\n",
        "class NonlinearTimeSeriesGeneratorIrregularConfounded:\n",
        "    def __init__(self, noise_type='student_t', noise_params={'scale': 0.1, 'df': 3},\n",
        "                 trend_strength=0.01, seasonal_strength=0.5, seasonal_period=12, random_state=None):\n",
        "        self.noise_type = noise_type\n",
        "        self.noise_params = noise_params\n",
        "        self.trend_strength = trend_strength\n",
        "        self.seasonal_strength = seasonal_strength\n",
        "        self.seasonal_period = seasonal_period\n",
        "        self.random_state = random_state\n",
        "        if random_state is not None:\n",
        "            np.random.seed(random_state)\n",
        "            stats.t.random_state = np.random.RandomState(random_state)\n",
        "\n",
        "    def generate_noise(self, size):\n",
        "        \"\"\"Generate noise based on specified distribution\"\"\"\n",
        "        if self.noise_type == 'gaussian':\n",
        "            return np.random.normal(0, self.noise_params['scale'], size=size)\n",
        "        elif self.noise_type == 'student_t':\n",
        "            return stats.t.rvs(df=self.noise_params['df'],\n",
        "                             loc=0,\n",
        "                             scale=self.noise_params['scale'],\n",
        "                             size=size)\n",
        "\n",
        "    def generate_irregular_timestamps(self, n_points, total_time, min_gap=0.1):\n",
        "        \"\"\"Generate irregular sampling times\"\"\"\n",
        "        times = np.zeros(n_points)\n",
        "        times[0] = np.random.uniform(0, min_gap)\n",
        "\n",
        "        for i in range(1, n_points):\n",
        "            gap = np.random.exponential(scale=(total_time-times[i-1])/(n_points-i))\n",
        "            times[i] = times[i-1] + max(gap, min_gap)\n",
        "\n",
        "            if times[i] > total_time:\n",
        "                times = times * (total_time / times[i])\n",
        "\n",
        "        return times\n",
        "\n",
        "    def generate_trend(self, n_points, var_idx):\n",
        "        \"\"\"Generate deterministic trend component\"\"\"\n",
        "        trend_modifier = (var_idx + 1) * 0.5\n",
        "        t = np.arange(n_points)\n",
        "        return self.trend_strength * trend_modifier * t\n",
        "\n",
        "    def generate_seasonality(self, timestamps, var_idx):\n",
        "        \"\"\"Generate seasonal component using continuous time\"\"\"\n",
        "        phase_shift = 2 * np.pi * var_idx / 8\n",
        "        season1 = np.sin(2 * np.pi * timestamps / self.seasonal_period + phase_shift)\n",
        "        season2 = 0.5 * np.cos(4 * np.pi * timestamps / self.seasonal_period + phase_shift)\n",
        "        return self.seasonal_strength * (season1 + season2)\n",
        "\n",
        "    def find_nearest_lag_idx(self, timestamps, current_idx, lag_time):\n",
        "        \"\"\"Find index of nearest available past observation for given lag\"\"\"\n",
        "        target_time = timestamps[current_idx] - lag_time\n",
        "        past_timestamps = timestamps[:current_idx]\n",
        "        if len(past_timestamps) == 0:\n",
        "            return 0\n",
        "        return (np.abs(past_timestamps - target_time)).argmin()\n",
        "    def evaluate_term(self, term, var_values, X, U, t, timestamps, lag_indices):\n",
        "        \"\"\"Evaluate a single term in the equation with irregular sampling\"\"\"\n",
        "        parts = term.split('*')\n",
        "        coef = float(parts[0].strip())\n",
        "        expr = parts[1].strip()\n",
        "\n",
        "        # Handle U terms first\n",
        "        if expr.startswith('U['):\n",
        "            if expr == 'U[t]':\n",
        "                if '^' in expr:\n",
        "                    power = int(expr.split('^')[1])\n",
        "                    return coef * (U[t] ** power)\n",
        "                return coef * U[t]\n",
        "            # U doesn't actually have lagged terms in our equations\n",
        "            return coef * U[t]\n",
        "\n",
        "        # Handle autocorrelation terms\n",
        "        if '[t-' in expr and not any(func in expr for func in ['cos', 'sin', '^']):\n",
        "            var_idx = int(expr[1]) - 1\n",
        "            lag = int(expr.split('-')[1].split(']')[0])\n",
        "            lag_idx = lag_indices[lag-1]\n",
        "            return coef * X[lag_idx, var_idx]\n",
        "\n",
        "        # Handle nonlinear terms\n",
        "        if 'cos(' in expr:\n",
        "            inner = expr.split('cos(')[1].split(')')[0]\n",
        "            var_idx = int(inner.split('X')[1].split('[')[0]) - 1\n",
        "            if '[t-' in inner:\n",
        "                lag = int(inner.split('-')[1].split(']')[0])\n",
        "                lag_idx = lag_indices[lag-1]\n",
        "                value = X[lag_idx, var_idx]\n",
        "            else:\n",
        "                value = X[t, var_idx]\n",
        "            return coef * np.cos(value * np.pi/2)\n",
        "        elif 'sin(' in expr:\n",
        "            inner = expr.split('sin(')[1].split(')')[0]\n",
        "            var_idx = int(inner.split('X')[1].split('[')[0]) - 1\n",
        "            if '[t-' in inner:\n",
        "                lag = int(inner.split('-')[1].split(']')[0])\n",
        "                lag_idx = lag_indices[lag-1]\n",
        "                value = X[lag_idx, var_idx]\n",
        "            else:\n",
        "                value = X[t, var_idx]\n",
        "            return coef * np.sin(value * np.pi/2)\n",
        "        elif '^' in expr:\n",
        "            power = int(expr.split('^')[1])\n",
        "            var_idx = int(expr.split('X')[1].split('[')[0]) - 1\n",
        "            if '[t-' in expr:\n",
        "                lag = int(expr.split('-')[1].split(']')[0])\n",
        "                lag_idx = lag_indices[lag-1]\n",
        "                value = X[lag_idx, var_idx]\n",
        "            else:\n",
        "                value = X[t, var_idx]\n",
        "            return coef * (value ** power)\n",
        "\n",
        "        # Default linear case\n",
        "        var_idx = int(expr.split('X')[1].split('[')[0]) - 1\n",
        "        if '[t-' in expr:\n",
        "            lag = int(expr.split('-')[1].split(']')[0])\n",
        "            lag_idx = lag_indices[lag-1]\n",
        "            value = X[lag_idx, var_idx]\n",
        "        else:\n",
        "            value = X[t, var_idx]\n",
        "        return coef * value\n",
        "\n",
        "    def generate_equations(self, t, X, U, trends, seasonality, n_vars, max_lag, timestamps, lag_indices):\n",
        "        \"\"\"Execute nonlinear equations with trends, seasonality, and confounder\"\"\"\n",
        "        noise = self.generate_noise(n_vars + 1)  # +1 for U\n",
        "        equations = get_nonlinear_equations_with_confounder(n_vars, max_lag)\n",
        "        var_values = {}\n",
        "\n",
        "        # Generate U first (confounder)\n",
        "        U[t] = noise[-1]\n",
        "        var_values['U'] = U[t]\n",
        "\n",
        "        for eq in equations:\n",
        "            if '=' not in eq or eq.startswith('U['):\n",
        "                continue\n",
        "\n",
        "            left, right = eq.split('=')\n",
        "            var_name = left.split('[')[0]\n",
        "            var_idx = int(var_name[1:]) - 1\n",
        "\n",
        "            terms = [term.strip() for term in right.split('+')]\n",
        "            value = 0\n",
        "\n",
        "            for term in terms:\n",
        "                if term.startswith('e'):  # Noise term\n",
        "                    value += noise[var_idx]\n",
        "                elif term.startswith('trend'):\n",
        "                    value += trends[var_idx][t]\n",
        "                elif term.startswith('season'):\n",
        "                    value += seasonality[var_idx][t]\n",
        "                else:\n",
        "                    value += self.evaluate_term(term, var_values, X, U, t, timestamps, lag_indices)\n",
        "\n",
        "            X[t, var_idx] = value\n",
        "            var_values[var_name] = value\n",
        "\n",
        "    def generate_multivariate_ts(self, n_points, n_vars, max_lag, total_time=100, min_gap=0.1):\n",
        "        \"\"\"Generate multivariate time series with irregular sampling and confounder\"\"\"\n",
        "        # Generate irregular timestamps\n",
        "        timestamps = self.generate_irregular_timestamps(n_points, total_time, min_gap)\n",
        "\n",
        "        # Initialize arrays\n",
        "        X = np.zeros((n_points, n_vars))\n",
        "        U = np.zeros(n_points)  # Array for confounder U\n",
        "\n",
        "        # Generate trends and seasonality components\n",
        "        trends = [self.generate_trend(n_points, i) for i in range(n_vars)]\n",
        "        seasonality = [self.generate_seasonality(timestamps, i) for i in range(n_vars)]\n",
        "\n",
        "        # Initialize first steps with noise\n",
        "        for i in range(max_lag):\n",
        "            X[i] = self.generate_noise(n_vars)\n",
        "            U[i] = self.generate_noise(1)[0]\n",
        "            # Add trend and seasonality to initial values\n",
        "            for j in range(n_vars):\n",
        "                X[i, j] += trends[j][i] + seasonality[j][i]\n",
        "\n",
        "        # Generate time series\n",
        "        for t in range(max_lag, n_points):\n",
        "            mean_diff = np.mean(np.diff(timestamps))\n",
        "            lag_indices = [self.find_nearest_lag_idx(timestamps, t, i * mean_diff)\n",
        "                         for i in range(1, max_lag + 1)]\n",
        "\n",
        "            self.generate_equations(t, X, U, trends, seasonality, n_vars, max_lag, timestamps, lag_indices)\n",
        "\n",
        "        # Create DataFrame\n",
        "        columns = [f'X{i+1}' for i in range(n_vars)]\n",
        "        df = pd.DataFrame(X, columns=columns)\n",
        "        df['U'] = U  # Add confounder column\n",
        "        df['time'] = timestamps\n",
        "\n",
        "        return df\n",
        "\n",
        "def extract_causal_links(equations):\n",
        "    \"\"\"Extract causal links from nonlinear equations including confounder\"\"\"\n",
        "    links = {}\n",
        "    for eq in equations:\n",
        "        if '=' not in eq or eq.startswith('U['):\n",
        "            continue\n",
        "\n",
        "        left, right = eq.split('=')\n",
        "        target = left.split('[')[0]\n",
        "\n",
        "        terms = right.split('+')\n",
        "        for term in terms:\n",
        "            term = term.strip()\n",
        "            if not ('X' in term or 'U' in term) or term.startswith('e'):\n",
        "                continue\n",
        "\n",
        "            coef = float(term.split('*')[0])\n",
        "\n",
        "            # Handle U terms\n",
        "            if 'U[' in term:\n",
        "                if '^' in term:\n",
        "                    power = int(term.split('^')[1])\n",
        "                    links[('U', 0, target, f'power{power}')] = coef\n",
        "                else:\n",
        "                    links[('U', 0, target, 'linear')] = coef\n",
        "                continue\n",
        "\n",
        "            # Handle X terms\n",
        "            if 'cos(' in term:\n",
        "                func = 'cos'\n",
        "                source = term.split('X')[1].split('[')[0]\n",
        "            elif 'sin(' in term:\n",
        "                func = 'sin'\n",
        "                source = term.split('X')[1].split('[')[0]\n",
        "            elif '^' in term:\n",
        "                func = f'power{term.split(\"^\")[1]}'\n",
        "                source = term.split('X')[1].split('[')[0]\n",
        "            else:\n",
        "                func = 'linear'\n",
        "                source = term.split('X')[1].split('[')[0]\n",
        "\n",
        "            if '[t-' in term:\n",
        "                lag = int(term.split('-')[1].split(']')[0])\n",
        "            else:\n",
        "                lag = 0\n",
        "\n",
        "            links[(f'X{source}', lag, target, func)] = coef\n",
        "\n",
        "    return links\n",
        "\n",
        "def save_dataset_and_graph(df, n_vars, max_lag, sample_size, noise_type, output_dir=\"output_nonlinear_irregular_confounded\"):\n",
        "    \"\"\"Save dataset and create visualizations including confounder\"\"\"\n",
        "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
        "    base_filename = f'{output_dir}/nonlinear_ts_n{sample_size}_vars{n_vars}_lag{max_lag}_{noise_type}'\n",
        "\n",
        "    # Save dataset\n",
        "    df.to_csv(f'{base_filename}.csv', index=False)\n",
        "\n",
        "    # Get equations and extract links\n",
        "    equations = get_nonlinear_equations_with_confounder(n_vars, max_lag)\n",
        "    true_links = extract_causal_links(equations)\n",
        "\n",
        "    # Create matrices for tigramite plotting\n",
        "    var_names = [f'X{i+1}' for i in range(n_vars)] + ['U']\n",
        "    n_total_vars = n_vars + 1\n",
        "    val_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1))\n",
        "    graph_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1), dtype='bool')\n",
        "\n",
        "    # Fill matrices based on true links\n",
        "    for (source, lag, target, func), weight in true_links.items():\n",
        "        if source == 'U':\n",
        "            source_idx = n_vars\n",
        "        else:\n",
        "            source_idx = int(source[1:]) - 1\n",
        "        target_idx = int(target[1:]) - 1\n",
        "        lag_idx = lag\n",
        "\n",
        "        # Add the link to the matrices\n",
        "        val_matrix[source_idx, target_idx, lag_idx] = weight\n",
        "        graph_matrix[source_idx, target_idx, lag_idx] = True\n",
        "\n",
        "        # For contemporaneous links, make val_matrix symmetric\n",
        "        if lag == 0:\n",
        "            val_matrix[target_idx, source_idx, lag_idx] = weight\n",
        "\n",
        "    # Plot and save causal graph\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    tp.plot_time_series_graph(\n",
        "        val_matrix=val_matrix,\n",
        "        graph=graph_matrix,\n",
        "        var_names=var_names,\n",
        "        link_colorbar_label='Nonlinear Effect Strength',\n",
        "        node_size=0.05\n",
        "    )\n",
        "    plt.title(f'Nonlinear Causal Graph with Confounder\\n(n={sample_size}, vars={n_vars}, lag={max_lag})')\n",
        "    plt.savefig(f'{base_filename}_graph.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot time series with irregular sampling\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for col in df.columns[:-2]:  # Exclude U and time\n",
        "        plt.plot(df['time'], df[col], label=col, marker='o', markersize=2, alpha=0.7)\n",
        "    # Plot confounder separately\n",
        "    plt.plot(df['time'], df['U'], label='U (confounder)',\n",
        "             linestyle='--', color='black', alpha=0.5)\n",
        "    plt.title(f'Nonlinear Time Series with Irregular Sampling and Confounder\\n(n={sample_size}, vars={n_vars}, lag={max_lag})')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Value')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{base_filename}_series.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Plot sampling intervals distribution\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    time_diffs = np.diff(df['time'])\n",
        "    plt.hist(time_diffs, bins=50, density=True)\n",
        "    plt.title('Distribution of Sampling Intervals')\n",
        "    plt.xlabel('Time Difference')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(f'{base_filename}_sampling.png')\n",
        "    plt.close()\n",
        "\n",
        "    # Save causal structure description\n",
        "    with open(f'{base_filename}_structure.txt', 'w') as f:\n",
        "        f.write(\"Nonlinear Causal Structure with Confounder:\\n\\n\")\n",
        "        f.write(\"Equations:\\n\")\n",
        "        for eq in equations:\n",
        "            f.write(f\"{eq}\\n\")\n",
        "        f.write(\"\\nCausal Links:\\n\")\n",
        "        for (source, lag, target, func), coef in true_links.items():\n",
        "            f.write(f\"{source} --({func}, lag={lag})--> {target}: {coef}\\n\")\n",
        "\n",
        "def generate_all_combinations():\n",
        "    \"\"\"Generate datasets for all combinations\"\"\"\n",
        "    sample_sizes = [500, 1000, 3000, 5000]\n",
        "    n_vars_list = [4, 6, 8]\n",
        "    max_lags = [2, 3, 4]\n",
        "    noise_types = ['gaussian', 'student_t']\n",
        "    trend_strengths = [0.01]\n",
        "    seasonal_strengths = [0.5]\n",
        "\n",
        "    for n in sample_sizes:\n",
        "        for vars_ in n_vars_list:\n",
        "            for lag in max_lags:\n",
        "                for noise_type in noise_types:\n",
        "                    for trend_str in trend_strengths:\n",
        "                        for seas_str in seasonal_strengths:\n",
        "                            print(f\"\\nGenerating dataset: n={n}, vars={vars_}, lag={lag}, \"\n",
        "                                  f\"noise={noise_type}, trend={trend_str}, seasonal={seas_str}\")\n",
        "\n",
        "                            # Configure noise parameters\n",
        "                            noise_params = {'scale': 0.1, 'df': 3} if noise_type == 'student_t' else {'scale': 0.1}\n",
        "\n",
        "                            # Initialize generator\n",
        "                            generator = NonlinearTimeSeriesGeneratorIrregularConfounded(\n",
        "                                noise_type=noise_type,\n",
        "                                noise_params=noise_params,\n",
        "                                trend_strength=trend_str,\n",
        "                                seasonal_strength=seas_str,\n",
        "                                seasonal_period=12,\n",
        "                                random_state=42\n",
        "                            )\n",
        "\n",
        "                            # Generate dataset\n",
        "                            df = generator.generate_multivariate_ts(\n",
        "                                n_points=n,\n",
        "                                n_vars=vars_,\n",
        "                                max_lag=lag,\n",
        "                                total_time=100,\n",
        "                                min_gap=0.1\n",
        "                            )\n",
        "\n",
        "                            # Save dataset and create visualizations\n",
        "                            save_dataset_and_graph(\n",
        "                                df=df,\n",
        "                                n_vars=vars_,\n",
        "                                max_lag=lag,\n",
        "                                sample_size=n,\n",
        "                                noise_type=noise_type\n",
        "                            )\n",
        "                            print(\"Dataset and visualizations saved successfully\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"Generating nonlinear time series with irregular sampling, mixed noise types, and confounder...\")\n",
        "    generate_all_combinations()\n",
        "    print(\"\\nAll datasets generated successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "upZlYmlIf99i",
        "outputId": "19c9106d-c4ff-4f9b-85e1-93b39ef6574a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating nonlinear time series with irregular sampling, mixed noise types, and confounder...\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=4, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=6, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=500, vars=8, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/tigramite/plotting.py:3203: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  fig = pyplot.figure(figsize=figsize)\n",
            "<ipython-input-4-0f72468d8166>:390: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(15, 10))\n",
            "<ipython-input-4-0f72468d8166>:405: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(10, 5))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-0f72468d8166>:377: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
            "  plt.figure(figsize=(12, 12))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=4, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=6, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=1000, vars=8, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=4, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=6, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=3000, vars=8, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=4, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=6, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=2, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=3, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, noise=gaussian, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "Generating dataset: n=5000, vars=8, lag=4, noise=student_t, trend=0.01, seasonal=0.5\n",
            "Dataset and visualizations saved successfully\n",
            "\n",
            "All datasets generated successfully!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Zip and download output\n",
        "!zip -r /content/output_nonlinear.zip /content/output_nonlinear_irregular_confounded\n",
        "from google.colab import files\n",
        "files.download('/content/output_nonlinear.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-K4di8xwgLzt",
        "outputId": "987bdad4-bf5d-4599-e672-7c2e361e9a20"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/output_nonlinear_irregular_confounded/ (stored 0%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_gaussian_series.png (deflated 6%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_gaussian_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_gaussian_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_student_t_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_student_t_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_student_t_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_student_t_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_gaussian_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_gaussian_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_gaussian_series.png (deflated 6%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_gaussian_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_gaussian_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_gaussian_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_student_t_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_student_t_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_gaussian_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_gaussian_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_student_t_series.png (deflated 6%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_student_t_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_gaussian_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_gaussian_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_student_t_graph.png (deflated 3%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_student_t_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_gaussian_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_student_t_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_student_t_graph.png (deflated 3%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_student_t_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_gaussian_series.png (deflated 6%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_student_t_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag2_student_t_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_gaussian_graph.png (deflated 3%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_student_t_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag3_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_gaussian_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_gaussian_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag2_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_student_t.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_student_t_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag2_student_t_structure.txt (deflated 57%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_student_t_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_student_t_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_student_t_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars6_lag4_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag2_student_t_series.png (deflated 7%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_gaussian.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_student_t_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag2_gaussian_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_gaussian_structure.txt (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag2_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_gaussian_structure.txt (deflated 62%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_gaussian_structure.txt (deflated 54%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag4_gaussian_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag2_gaussian_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars8_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag4_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars6_lag3_student_t_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_gaussian_graph.png (deflated 4%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_gaussian.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag2_gaussian.csv (deflated 50%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag4_student_t.csv (deflated 51%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag3_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag2_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_student_t_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars4_lag3_gaussian_series.png (deflated 8%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_gaussian_series.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars4_lag3_student_t_sampling.png (deflated 25%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n1000_vars8_lag4_gaussian_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_student_t_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag4_gaussian_structure.txt (deflated 63%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag3_gaussian_sampling.png (deflated 24%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag4_student_t.csv (deflated 52%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag4_student_t_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars8_lag4_gaussian_series.png (deflated 9%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars6_lag4_student_t_structure.txt (deflated 58%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars4_lag3_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n5000_vars6_lag4_gaussian_series.png (deflated 10%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n500_vars8_lag2_student_t_graph.png (deflated 5%)\n",
            "  adding: content/output_nonlinear_irregular_confounded/nonlinear_ts_n3000_vars4_lag3_gaussian_graph.png (deflated 3%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c3b061a6-7504-4015-87db-b0ccc4bc72c7\", \"output_nonlinear.zip\", 27193009)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}