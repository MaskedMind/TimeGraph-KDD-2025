# -*- coding: utf-8 -*-
"""C2C.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tmzRtQeB8Mnk14wu5Lw2QJdtc3uCr7xH
"""

!pip install tigramite

import numpy as np
import pandas as pd
from scipy import stats
from tigramite import plotting as tp
import matplotlib.pyplot as plt
from pathlib import Path

def get_nonlinear_equations_with_confounder(n_vars, max_lag):
    """Get nonlinear equations with confounder U (max 2 edges from U)"""
    if n_vars == 4:
        if max_lag == 2:
            return [
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 3:
            return [
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 4:
            return [
                "X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + 0.3 * U[t]^2 + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
    elif n_vars == 6:
        if max_lag == 2:
            return [
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 3:
            return [
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 4:
            return [
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + 0.4 * U[t]^2 + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
    elif n_vars == 8:
        if max_lag == 2:
            return [
                "X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8",
                "X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7",
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 3:
            return [
                "X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8",
                "X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7",
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-2] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
        elif max_lag == 4:
            return [
                "X8[t] = 0.4 * sin(X7[t] * pi/2) + 0.35 * U[t]^2 + trend8[t] + season8[t] + e8",
                "X7[t] = 0.35 * cos(X6[t-1] * pi/2) + trend7[t] + season7[t] + e7",
                "X6[t] = 0.85 * sin(X5[t] * pi/2) + trend6[t] + season6[t] + e6",
                "X5[t] = 0.3 * cos(X4[t-1] * pi/2) + trend5[t] + season5[t] + e5",
                "X4[t] = 0.25 * cos(X1[t-4] * pi/2) + trend4[t] + season4[t] + e4",
                "X3[t] = 0.35 * (X4[t])^2 + 0.2 * cos(X2[t-3] * pi/2) + trend3[t] + season3[t] + e3",
                "X2[t] = 0.3 * sin(X3[t-1] * pi/2) + trend2[t] + season2[t] + e2",
                "X1[t] = 0.4 * (X2[t])^3 + 0.5 * U[t]^2 + trend1[t] + season1[t] + e1",
                "U[t] = eU"
            ]
    return []

class NonlinearTimeSeriesGeneratorIrregularConfounded:
    def __init__(self, noise_type='student_t', noise_params={'scale': 0.1, 'df': 3},
                 trend_strength=0.01, seasonal_strength=0.5, seasonal_period=12, random_state=None):
        self.noise_type = noise_type
        self.noise_params = noise_params
        self.trend_strength = trend_strength
        self.seasonal_strength = seasonal_strength
        self.seasonal_period = seasonal_period
        self.random_state = random_state
        if random_state is not None:
            np.random.seed(random_state)
            stats.t.random_state = np.random.RandomState(random_state)

    def generate_noise(self, size):
        """Generate noise based on specified distribution"""
        if self.noise_type == 'gaussian':
            return np.random.normal(0, self.noise_params['scale'], size=size)
        elif self.noise_type == 'student_t':
            return stats.t.rvs(df=self.noise_params['df'],
                             loc=0,
                             scale=self.noise_params['scale'],
                             size=size)

    def generate_irregular_timestamps(self, n_points, total_time, min_gap=0.1):
        """Generate irregular sampling times"""
        times = np.zeros(n_points)
        times[0] = np.random.uniform(0, min_gap)

        for i in range(1, n_points):
            gap = np.random.exponential(scale=(total_time-times[i-1])/(n_points-i))
            times[i] = times[i-1] + max(gap, min_gap)

            if times[i] > total_time:
                times = times * (total_time / times[i])

        return times

    def generate_trend(self, n_points, var_idx):
        """Generate deterministic trend component"""
        trend_modifier = (var_idx + 1) * 0.5
        t = np.arange(n_points)
        return self.trend_strength * trend_modifier * t

    def generate_seasonality(self, timestamps, var_idx):
        """Generate seasonal component using continuous time"""
        phase_shift = 2 * np.pi * var_idx / 8
        season1 = np.sin(2 * np.pi * timestamps / self.seasonal_period + phase_shift)
        season2 = 0.5 * np.cos(4 * np.pi * timestamps / self.seasonal_period + phase_shift)
        return self.seasonal_strength * (season1 + season2)

    def find_nearest_lag_idx(self, timestamps, current_idx, lag_time):
        """Find index of nearest available past observation for given lag"""
        target_time = timestamps[current_idx] - lag_time
        past_timestamps = timestamps[:current_idx]
        if len(past_timestamps) == 0:
            return 0
        return (np.abs(past_timestamps - target_time)).argmin()
    def evaluate_term(self, term, var_values, X, U, t, timestamps, lag_indices):
        """Evaluate a single term in the equation with irregular sampling"""
        parts = term.split('*')
        coef = float(parts[0].strip())
        expr = parts[1].strip()

        # Handle U terms first
        if expr.startswith('U['):
            if expr == 'U[t]':
                if '^' in expr:
                    power = int(expr.split('^')[1])
                    return coef * (U[t] ** power)
                return coef * U[t]
            # U doesn't actually have lagged terms in our equations
            return coef * U[t]

        # Handle autocorrelation terms
        if '[t-' in expr and not any(func in expr for func in ['cos', 'sin', '^']):
            var_idx = int(expr[1]) - 1
            lag = int(expr.split('-')[1].split(']')[0])
            lag_idx = lag_indices[lag-1]
            return coef * X[lag_idx, var_idx]

        # Handle nonlinear terms
        if 'cos(' in expr:
            inner = expr.split('cos(')[1].split(')')[0]
            var_idx = int(inner.split('X')[1].split('[')[0]) - 1
            if '[t-' in inner:
                lag = int(inner.split('-')[1].split(']')[0])
                lag_idx = lag_indices[lag-1]
                value = X[lag_idx, var_idx]
            else:
                value = X[t, var_idx]
            return coef * np.cos(value * np.pi/2)
        elif 'sin(' in expr:
            inner = expr.split('sin(')[1].split(')')[0]
            var_idx = int(inner.split('X')[1].split('[')[0]) - 1
            if '[t-' in inner:
                lag = int(inner.split('-')[1].split(']')[0])
                lag_idx = lag_indices[lag-1]
                value = X[lag_idx, var_idx]
            else:
                value = X[t, var_idx]
            return coef * np.sin(value * np.pi/2)
        elif '^' in expr:
            power = int(expr.split('^')[1])
            var_idx = int(expr.split('X')[1].split('[')[0]) - 1
            if '[t-' in expr:
                lag = int(expr.split('-')[1].split(']')[0])
                lag_idx = lag_indices[lag-1]
                value = X[lag_idx, var_idx]
            else:
                value = X[t, var_idx]
            return coef * (value ** power)

        # Default linear case
        var_idx = int(expr.split('X')[1].split('[')[0]) - 1
        if '[t-' in expr:
            lag = int(expr.split('-')[1].split(']')[0])
            lag_idx = lag_indices[lag-1]
            value = X[lag_idx, var_idx]
        else:
            value = X[t, var_idx]
        return coef * value

    def generate_equations(self, t, X, U, trends, seasonality, n_vars, max_lag, timestamps, lag_indices):
        """Execute nonlinear equations with trends, seasonality, and confounder"""
        noise = self.generate_noise(n_vars + 1)  # +1 for U
        equations = get_nonlinear_equations_with_confounder(n_vars, max_lag)
        var_values = {}

        # Generate U first (confounder)
        U[t] = noise[-1]
        var_values['U'] = U[t]

        for eq in equations:
            if '=' not in eq or eq.startswith('U['):
                continue

            left, right = eq.split('=')
            var_name = left.split('[')[0]
            var_idx = int(var_name[1:]) - 1

            terms = [term.strip() for term in right.split('+')]
            value = 0

            for term in terms:
                if term.startswith('e'):  # Noise term
                    value += noise[var_idx]
                elif term.startswith('trend'):
                    value += trends[var_idx][t]
                elif term.startswith('season'):
                    value += seasonality[var_idx][t]
                else:
                    value += self.evaluate_term(term, var_values, X, U, t, timestamps, lag_indices)

            X[t, var_idx] = value
            var_values[var_name] = value

    def generate_multivariate_ts(self, n_points, n_vars, max_lag, total_time=100, min_gap=0.1):
        """Generate multivariate time series with irregular sampling and confounder"""
        # Generate irregular timestamps
        timestamps = self.generate_irregular_timestamps(n_points, total_time, min_gap)

        # Initialize arrays
        X = np.zeros((n_points, n_vars))
        U = np.zeros(n_points)  # Array for confounder U

        # Generate trends and seasonality components
        trends = [self.generate_trend(n_points, i) for i in range(n_vars)]
        seasonality = [self.generate_seasonality(timestamps, i) for i in range(n_vars)]

        # Initialize first steps with noise
        for i in range(max_lag):
            X[i] = self.generate_noise(n_vars)
            U[i] = self.generate_noise(1)[0]
            # Add trend and seasonality to initial values
            for j in range(n_vars):
                X[i, j] += trends[j][i] + seasonality[j][i]

        # Generate time series
        for t in range(max_lag, n_points):
            mean_diff = np.mean(np.diff(timestamps))
            lag_indices = [self.find_nearest_lag_idx(timestamps, t, i * mean_diff)
                         for i in range(1, max_lag + 1)]

            self.generate_equations(t, X, U, trends, seasonality, n_vars, max_lag, timestamps, lag_indices)

        # Create DataFrame
        columns = [f'X{i+1}' for i in range(n_vars)]
        df = pd.DataFrame(X, columns=columns)
        df['U'] = U  # Add confounder column
        df['time'] = timestamps

        return df

def extract_causal_links(equations):
    """Extract causal links from nonlinear equations including confounder"""
    links = {}
    for eq in equations:
        if '=' not in eq or eq.startswith('U['):
            continue

        left, right = eq.split('=')
        target = left.split('[')[0]

        terms = right.split('+')
        for term in terms:
            term = term.strip()
            if not ('X' in term or 'U' in term) or term.startswith('e'):
                continue

            coef = float(term.split('*')[0])

            # Handle U terms
            if 'U[' in term:
                if '^' in term:
                    power = int(term.split('^')[1])
                    links[('U', 0, target, f'power{power}')] = coef
                else:
                    links[('U', 0, target, 'linear')] = coef
                continue

            # Handle X terms
            if 'cos(' in term:
                func = 'cos'
                source = term.split('X')[1].split('[')[0]
            elif 'sin(' in term:
                func = 'sin'
                source = term.split('X')[1].split('[')[0]
            elif '^' in term:
                func = f'power{term.split("^")[1]}'
                source = term.split('X')[1].split('[')[0]
            else:
                func = 'linear'
                source = term.split('X')[1].split('[')[0]

            if '[t-' in term:
                lag = int(term.split('-')[1].split(']')[0])
            else:
                lag = 0

            links[(f'X{source}', lag, target, func)] = coef

    return links

def save_dataset_and_graph(df, n_vars, max_lag, sample_size, noise_type, output_dir="output_nonlinear_irregular_confounded"):
    """Save dataset and create visualizations including confounder"""
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    base_filename = f'{output_dir}/nonlinear_ts_n{sample_size}_vars{n_vars}_lag{max_lag}_{noise_type}'

    # Save dataset
    df.to_csv(f'{base_filename}.csv', index=False)

    # Get equations and extract links
    equations = get_nonlinear_equations_with_confounder(n_vars, max_lag)
    true_links = extract_causal_links(equations)

    # Create matrices for tigramite plotting
    var_names = [f'X{i+1}' for i in range(n_vars)] + ['U']
    n_total_vars = n_vars + 1
    val_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1))
    graph_matrix = np.zeros((n_total_vars, n_total_vars, max_lag + 1), dtype='bool')

    # Fill matrices based on true links
    for (source, lag, target, func), weight in true_links.items():
        if source == 'U':
            source_idx = n_vars
        else:
            source_idx = int(source[1:]) - 1
        target_idx = int(target[1:]) - 1
        lag_idx = lag

        # Add the link to the matrices
        val_matrix[source_idx, target_idx, lag_idx] = weight
        graph_matrix[source_idx, target_idx, lag_idx] = True

        # For contemporaneous links, make val_matrix symmetric
        if lag == 0:
            val_matrix[target_idx, source_idx, lag_idx] = weight

    # Plot and save causal graph
    plt.figure(figsize=(12, 12))
    tp.plot_time_series_graph(
        val_matrix=val_matrix,
        graph=graph_matrix,
        var_names=var_names,
        link_colorbar_label='Nonlinear Effect Strength',
        node_size=0.05
    )
    plt.title(f'Nonlinear Causal Graph with Confounder\n(n={sample_size}, vars={n_vars}, lag={max_lag})')
    plt.savefig(f'{base_filename}_graph.png')
    plt.close()

    # Plot time series with irregular sampling
    plt.figure(figsize=(15, 10))
    for col in df.columns[:-2]:  # Exclude U and time
        plt.plot(df['time'], df[col], label=col, marker='o', markersize=2, alpha=0.7)
    # Plot confounder separately
    plt.plot(df['time'], df['U'], label='U (confounder)',
             linestyle='--', color='black', alpha=0.5)
    plt.title(f'Nonlinear Time Series with Irregular Sampling and Confounder\n(n={sample_size}, vars={n_vars}, lag={max_lag})')
    plt.xlabel('Time')
    plt.ylabel('Value')
    plt.legend()
    plt.grid(True)
    plt.savefig(f'{base_filename}_series.png')
    plt.close()

    # Plot sampling intervals distribution
    plt.figure(figsize=(10, 5))
    time_diffs = np.diff(df['time'])
    plt.hist(time_diffs, bins=50, density=True)
    plt.title('Distribution of Sampling Intervals')
    plt.xlabel('Time Difference')
    plt.ylabel('Density')
    plt.grid(True)
    plt.savefig(f'{base_filename}_sampling.png')
    plt.close()

    # Save causal structure description
    with open(f'{base_filename}_structure.txt', 'w') as f:
        f.write("Nonlinear Causal Structure with Confounder:\n\n")
        f.write("Equations:\n")
        for eq in equations:
            f.write(f"{eq}\n")
        f.write("\nCausal Links:\n")
        for (source, lag, target, func), coef in true_links.items():
            f.write(f"{source} --({func}, lag={lag})--> {target}: {coef}\n")

def generate_all_combinations():
    """Generate datasets for all combinations"""
    sample_sizes = [500, 1000, 3000, 5000]
    n_vars_list = [4, 6, 8]
    max_lags = [2, 3, 4]
    noise_types = ['gaussian', 'student_t']
    trend_strengths = [0.01]
    seasonal_strengths = [0.5]

    for n in sample_sizes:
        for vars_ in n_vars_list:
            for lag in max_lags:
                for noise_type in noise_types:
                    for trend_str in trend_strengths:
                        for seas_str in seasonal_strengths:
                            print(f"\nGenerating dataset: n={n}, vars={vars_}, lag={lag}, "
                                  f"noise={noise_type}, trend={trend_str}, seasonal={seas_str}")

                            # Configure noise parameters
                            noise_params = {'scale': 0.1, 'df': 3} if noise_type == 'student_t' else {'scale': 0.1}

                            # Initialize generator
                            generator = NonlinearTimeSeriesGeneratorIrregularConfounded(
                                noise_type=noise_type,
                                noise_params=noise_params,
                                trend_strength=trend_str,
                                seasonal_strength=seas_str,
                                seasonal_period=12,
                                random_state=42
                            )

                            # Generate dataset
                            df = generator.generate_multivariate_ts(
                                n_points=n,
                                n_vars=vars_,
                                max_lag=lag,
                                total_time=100,
                                min_gap=0.1
                            )

                            # Save dataset and create visualizations
                            save_dataset_and_graph(
                                df=df,
                                n_vars=vars_,
                                max_lag=lag,
                                sample_size=n,
                                noise_type=noise_type
                            )
                            print("Dataset and visualizations saved successfully")

if __name__ == "__main__":
    print("Generating nonlinear time series with irregular sampling, mixed noise types, and confounder...")
    generate_all_combinations()
    print("\nAll datasets generated successfully!")

# Optional: Zip and download output
!zip -r /content/output_nonlinear.zip /content/output_nonlinear_irregular_confounded
from google.colab import files
files.download('/content/output_nonlinear.zip')